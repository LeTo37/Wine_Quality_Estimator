{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Predictor\n",
    "\n",
    "## Process Followed\n",
    "* Data is read\n",
    "* Data is formatted into Features and Quality (output)\n",
    "* An additional column of data is added - has a label for excellent, average and bad wines\n",
    "    * Becomes a classification problem\n",
    "* Data is split into K-folds of training and testing data for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikas/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data\n",
    "\n",
    "The data is read according to the feature name and split accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    '''This function reads the winequality datasets and appends the\n",
    "    results into the appropriate feature and output arrays'''\n",
    "    df1 = pd.read_csv('winequality-red.csv')\n",
    "    df2 = pd.read_csv('winequality-white.csv')\n",
    "    data = pd.concat([df1, df2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file(\"winequality-red.csv\")\n",
    "read_file(\"winequality-white.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values for df1 are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1599, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The values for df1 are')\n",
    "df1.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values for df2 are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4898, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The values for df2 are\")\n",
    "df2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different features are joined into one numpy array of all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = np.ones((len(x1),11))\n",
    "y = np.array(y)\n",
    "y = np.reshape(y,(y.size,1))\n",
    "Features[:,0] = x1\n",
    "Features[:,1] = x2\n",
    "Features[:,2] = x3\n",
    "Features[:,3] = x4\n",
    "Features[:,4] = x5\n",
    "Features[:,5] = x6\n",
    "Features[:,6] = x7\n",
    "Features[:,7] = x8\n",
    "Features[:,8] = x9\n",
    "Features[:,9] = x10\n",
    "Features[:,10] = x11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn this into a classification problem with 3 classes, whereby wine with a quality between 0 and 4 is \"bad\" (label = 0), between 5 and 6 is \"average\" (label = 1) and between 7 and 10 is \"exceptional\" (label = 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabel = np.ones((y.shape))\n",
    "for i in range(0,y.size):\n",
    "    if (y[i] < 5):\n",
    "        ylabel[i] = 0\n",
    "    elif (y[i] < 7):\n",
    "        ylabel[i] = 1\n",
    "    else:\n",
    "        ylabel[i] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold Cross Validation\n",
    "Performing a K-fold split for training and testing data, k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(x,y,k=3):\n",
    "    '''This function takes the full data set of features and labels/output\n",
    "    and splits the set into k=3 sections, whereby 2/3 is used for training and \n",
    "    the 1/3 for testing. It rotates these folds such each set is used for both \n",
    "    training and testing'''\n",
    "    testx = np.zeros((k,int(round(x.shape[0]/k))+1,x.shape[1])) # +1 because x.shape[0]/3 is not whole\n",
    "    testy = np.zeros((k,int(round(x.shape[0]/k))+1,y.shape[1]))\n",
    "    trainx = np.zeros((k,int(((k-1)*round(x.shape[0]/k)))+1,x.shape[1]))\n",
    "    trainy = np.zeros((k,int(((k-1)*round(x.shape[0]/k)))+1,y.shape[1]))\n",
    "    i = np.random.choice(range(x.shape[0]),x.shape[0],replace = False)\n",
    "    for h in range(0,k):\n",
    "        xtemp = np.copy(x)\n",
    "        ytemp = np.copy(y)\n",
    "        testx_temp = np.zeros((int(round(x.shape[0]/k))+1,x.shape[1]))\n",
    "        testy_temp = np.zeros((int(round(x.shape[0]/k))+1,y.shape[1]))\n",
    "        trainx_temp = np.zeros((int(((k-1)*round(x.shape[0]/k)))+1,x.shape[1]))\n",
    "        trainy_temp = np.zeros((int(((k-1)*round(x.shape[0]/k)))+1,y.shape[1]))\n",
    "        l=int((i.size/k)*(h+1))\n",
    "        count = 0\n",
    "        for j in range(0,i.size):\n",
    "            if ((j)+int(i.size/k)*(h) < l):\n",
    "                testx_temp[j] = (np.take(xtemp,i[(j)+int(i.size/k)*(h)],axis=0))\n",
    "                testy_temp[j] = (np.take(ytemp,i[(j)+int(i.size/k)*(h)]))\n",
    "            else:\n",
    "                trainx_temp[count] = (np.take(xtemp,i[j],axis=0))\n",
    "                trainy_temp[count] = (np.take(ytemp,i[j]))\n",
    "                count+=1\n",
    "        testx[h] = testx_temp\n",
    "        testy[h] = testy_temp\n",
    "        trainx[h] = trainx_temp\n",
    "        trainy[h] = trainy_temp\n",
    "    return trainx,trainy,testx,testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of the training and testing data after the K-fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testx has the following shape: (3, 2167, 11)\n",
      "testy has the following shape: (3, 2167)\n",
      "trainx has the following shape: (3, 4333, 11)\n",
      "trainy has the following shape: (3, 4333)\n"
     ]
    }
   ],
   "source": [
    "trainx,trainy,testx,testy = k_fold_split(Features,ylabel)\n",
    "#reshape for sklearn\n",
    "testy = np.reshape(testy,(testy.shape[0],testy.shape[1],))\n",
    "trainy = np.reshape(trainy,(trainy.shape[0],trainy.shape[1],))\n",
    "print(\"testx has the following shape: \" + str(testx.shape))\n",
    "print(\"testy has the following shape: \" + str(testy.shape))\n",
    "print(\"trainx has the following shape: \" + str(trainx.shape))\n",
    "print(\"trainy has the following shape: \" + str(trainy.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model,trainx,trainy,testx,testy):\n",
    "    stime = time.time()\n",
    "    algorithm = model.fit(trainx,trainy)\n",
    "    etime = time.time()\n",
    "    train_time = etime-stime\n",
    "#     print(\"training time = \"+ str(train_time))    \n",
    "    \n",
    "    stime = time.time()\n",
    "    prediction = algorithm.predict(testx)\n",
    "    etime = time.time()\n",
    "    train_time = etime-stime\n",
    "#     print(\"testing time = \"+ str(train_time))\n",
    "    \n",
    "    accuracy = accuracy_score(testy,prediction)\n",
    "#     print(\"The accuracy of this prediction is: \" + str(accuracy))\n",
    "    return algorithm,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestK_retrain(model,trainx,trainy,testx,testy):\n",
    "    stime = time.time()\n",
    "    mod = []\n",
    "    acc = []\n",
    "    for k in range(0,trainx.shape[0]):\n",
    "        mod_k,acc_k = train_and_test(model,trainx[k],trainy[k],testx[k],testy[k])\n",
    "        mod.append(mod_k)\n",
    "        acc.append(acc_k)\n",
    "    acc = np.array(acc)\n",
    "    ind = np.argmax(acc)\n",
    "    best_mod = mod[ind]\n",
    "    best_pred = best_mod.predict(Features)\n",
    "    best_acc = accuracy_score(ylabel,best_pred)\n",
    "    print(\"The best accuracy achieved for \"+ best_mod.__class__.__name__+ \" is: \" + str(best_acc))\n",
    "    etime = time.time()\n",
    "    tot_time = etime-stime\n",
    "    print(\"Time taken for \"+ best_mod.__class__.__name__+ \" model= \"+ str(tot_time))\n",
    "    return best_mod,best_acc,tot_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models():\n",
    "    Gaussian_model= GaussianNB()\n",
    "    LogReg_model = LogisticRegression()\n",
    "    DTree_model = tree.DecisionTreeClassifier()\n",
    "    RForest_model = RandomForestClassifier(n_estimators=1000)\n",
    "    KNN_model = KNeighborsClassifier()\n",
    "    Net_model = MLPClassifier(alpha = 1)\n",
    "    list_models = [Gaussian_model,LogReg_model,DTree_model,RForest_model,KNN_model,Net_model]  \n",
    "    models = []\n",
    "    accs = []\n",
    "    times = []\n",
    "    for i in list_models:\n",
    "        mod_i, acc_i,times_i = bestK_retrain(i,trainx,trainy,testx,testy)\n",
    "        print(\"\")\n",
    "        models.append(mod_i)\n",
    "        accs.append(acc_i)\n",
    "        times.append(times_i)\n",
    "    \n",
    "    return models,accs,times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy achieved for GaussianNB is: 0.7181776204402032\n",
      "Time taken for GaussianNB model= 0.03210282325744629\n",
      "\n",
      "The best accuracy achieved for LogisticRegression is: 0.7823610897337232\n",
      "Time taken for LogisticRegression model= 0.20830845832824707\n",
      "\n",
      "The best accuracy achieved for DecisionTreeClassifier is: 0.9251962444205017\n",
      "Time taken for DecisionTreeClassifier model= 0.09764671325683594\n",
      "\n",
      "The best accuracy achieved for RandomForestClassifier is: 0.9492073264583654\n",
      "Time taken for RandomForestClassifier model= 19.549546480178833\n",
      "\n",
      "The best accuracy achieved for KNeighborsClassifier is: 0.8025242419578267\n",
      "Time taken for KNeighborsClassifier model= 0.08058309555053711\n",
      "\n",
      "The best accuracy achieved for MLPClassifier is: 0.7682007080190857\n",
      "Time taken for MLPClassifier model= 1.3030085563659668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models,accs,times = test_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the best accuray is RandomForestClassifier\n",
      "The model with the fastest processing is GaussianNB\n"
     ]
    }
   ],
   "source": [
    "models = np.array(models)\n",
    "accs = np.array(accs)\n",
    "times = np.array(times)\n",
    "acc_ind = np.argmax(accs)\n",
    "time_ind = np.argmin(times)\n",
    "print(\"The model with the best accuray is \" + models[acc_ind].__class__.__name__)\n",
    "print(\"The model with the fastest processing is \" + models[time_ind].__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
